{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "train_batch_size = 32\n",
    "test_batch_size = 124\n",
    "best_loss = float(\"inf\")\n",
    "best_epoch = -1\n",
    "dataset_path = './cifar10'\n",
    "gsync_save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "except ModuleNotFoundError:\n",
    "    from os import path\n",
    "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "    accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.1-{platform}-linux_x86_64.whl\n",
    "    import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "try:\n",
    "    import torchvision\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -q torchvision\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "if gsync_save:\n",
    "    try:\n",
    "        import utils\n",
    "    except ModuleNotFoundError:\n",
    "        !wget https://raw.githubusercontent.com/StefOe/colab-pytorch-utils/HEAD/utils.py\n",
    "        import utils\n",
    "\n",
    "    gsync = utils.GDriveSync()\n",
    "\n",
    "\n",
    "try:\n",
    "    from allconv import AllConvNet\n",
    "except ModuleNotFoundError:\n",
    "    !wget https://github.com/StefOe/all-conv-pytorch/raw/HEAD/allconv.py\n",
    "    from allconv import AllConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = cuda and torch.cuda.is_available()\n",
    "\n",
    "trainset = datasets.CIFAR10(root=dataset_path, train=True, download=True)\n",
    "train_mean = trainset.data.mean(axis=(0, 1, 2)) / 255\n",
    "train_std = trainset.data.std(axis=(0, 1, 2)) / 255\n",
    "\n",
    "\n",
    "# Data normal (32x32)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "])\n",
    "\n",
    "\n",
    "#  transformaciones con 8x8\n",
    "\n",
    "transform_train8x8 = transforms.Compose([\n",
    "    transforms.Resize((8,8)),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "])\n",
    "\n",
    "transform_test8x8 = transforms.Compose([\n",
    "    transforms.Resize((8,8)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "])\n",
    "\n",
    "transform_32x32 = transforms.Compose([transforms.Resize((32,32)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "transform_16x16 = transforms.Compose([transforms.Resize((16,16)),\n",
    "    transforms.ToTensor()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "# Data normal\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(datasets.CIFAR10(\n",
    "    root=dataset_path, train=True, download=True,\n",
    "    transform=transform_train),\n",
    "    batch_size=train_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root=dataset_path, train=False, download=True,\n",
    "    transform=transform_test),\n",
    "    batch_size=test_batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data blurreada\n",
    "\n",
    "train_loader_blur = torch.utils.data.DataLoader(datasets.CIFAR10(\n",
    "    root=dataset_path, train=True, download=True,\n",
    "    transform=transform_train8x8),\n",
    "    batch_size=train_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader_blur = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root=dataset_path, train=False, download=True,\n",
    "    transform=transform_test8x8),\n",
    "    batch_size=test_batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "for batch_data, batch_labels in train_loader_blur:\n",
    "    resized_to_32x32 = transform_32x32(batch_data)\n",
    "\n",
    "for batch_data, batch_labels in test_loader_blur:\n",
    "    resized_to_32x32 = transform_32x32(batch_data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
